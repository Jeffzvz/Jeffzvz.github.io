---
Title: ğŸ˜¶DAB-DETR
Passage title: DYNAMIC ANCHOR BOXES  ARE BETTER QUERIES FOR DETR
Journal/Conference : ICLR2022
Date: 2024-07-31
Tags: ["Object Detection","DETRç³»åˆ—"]

---

## 1 Queryçš„è§’è‰²

![](picture_saved/2024-07-31-17-05-15-image.png)

å…ˆæ¥å›é¡¾ä¸€ä¸‹queryæ˜¯ä»€ä¹ˆï¼Œä¸Šå›¾æ˜¯encoderä¸­self-attentionå’Œdecoderä¸­cross-attentionçš„å¯¹æ¯”å›¾ï¼Œå¯ä»¥å‘ç°å”¯ä¸€çš„åŒºåˆ«åœ¨äºqueryçš„ç»„æˆã€‚å¯¹äºencoderçš„self-attentionï¼Œquery=image featuresï¼ˆå†…å®¹ï¼‰ + positional embeddingsï¼ˆä½ç½®ï¼‰ï¼Œæ‰€ä»¥å¯¹åº”åˆ°decoderæ¥è¯´ï¼Œdecoder embeddingså°±æ˜¯contentï¼Œlearnable querieså°±æ˜¯positionã€‚

å¯¹äºdecoder embeddingï¼Œå®ƒæ‹…å½“ä¸€ä¸ªâ€œè¯­ä¹‰è½½ä½“â€çš„èº«ä»½ï¼Œå®ƒæ˜¯ä¸å¯å­¦ä¹ çš„ï¼Œå®ƒé€šè¿‡cross attentionå’Œimage featureè¿›è¡Œäº¤äº’ï¼Œå¹¶å°†æ³¨æ„åŠ›æ–½åŠ åˆ°valuesä¸­ï¼ˆä¹Ÿæ˜¯image featuresï¼‰,ä»è€ŒæŠ½å–è¯­ä¹‰ä¿¡æ¯ã€‚

å¯¹äºlearnable queriesï¼Œå®ƒæ˜¯å¯å­¦ä¹ çš„ï¼Œä¹Ÿæ˜¯é€šè¿‡cross attentionè¿›è¡Œäº¤äº’ï¼ˆä¸æ–­åœ°çœ‹å›¾åƒä¸­çš„æŸä¸ªä¸œè¥¿ï¼‰ï¼Œæœ€åç”±ç›®æ ‡æŸå¤±å‡½æ•°åå‘ä¼ æ’­å›æ¥çš„æ¢¯åº¦è¿›è¡Œæ›´æ–°ï¼Œç†åº”è¦å­¦ä¹ åˆ°ç‰©ä½“çš„æ‰€åœ¨ä½ç½®ã€‚

## 1.1 Queryçš„ä¸å¥½

Encoderä¸­çš„queryæ˜¯å›¾åƒç‰¹å¾+æ­£ä½™å¼¦ç¼–ç ï¼Œæˆ‘ä»¬çŸ¥é“decoder embeddingåˆå§‹åŒ–ä¸º0ï¼Œlearnable queriesåˆæ²¡æœ‰æ˜¾ç¤ºæä¾›ä½ç½®å…ˆéªŒï¼Œå› æ­¤åˆšå¼€å§‹åšæ³¨æ„åŠ›æ—¶ï¼Œå¤§å¤šæ•°decoder embeddingséƒ½ä¼šè¢«projectåˆ°å›¾åƒç‰¹å¾çš„åŒä¸€ç©ºé—´ä½ç½®ï¼ˆlearnable queriesæ²¡æœ‰çº¦æŸä¹‹ï¼‰ï¼ŒDETRåŠ¿å¿…è¦ç»è¿‡å¤šè½®æ‰èƒ½è®­ç»ƒå¾—å½“ã€‚

é”™åœ¨learnable queriesï¼Œä½†æ˜¯åˆ°åº•æ˜¯learnable querieséš¾ä»¥å­¦ä¹ ï¼Œè¿˜æ˜¯è¯´å®ƒæ²¡æœ‰æä¾›æ˜¾ç¤ºä½ç½®å…ˆéªŒï¼Œæ‰è®©æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹æ¼«é•¿å‘¢ï¼Ÿ

![](picture_saved/2024-07-31-17-17-51-image.png)

ç”±æ”¹å›¾å¯çŸ¥ï¼Œæ‹¿äº†å·²è®­ç»ƒå¥½çš„DETRçš„learnable querieså¹¶å°†å…¶å›ºå®šä½ï¼Œç„¶åé‡æ–°è®­ç»ƒDETRçš„å…¶ä»–éƒ¨åˆ†ï¼Œé™¤äº†åœ¨å‰å‡ ä¸ªepochsçš„lossä¼šå°ä¸€ç‚¹ï¼Œæ•´ä½“è¿‡ç¨‹éƒ½åé¢è·ŸåŸå§‹learnable queriesçš„DETRå·®ä¸å¤šã€‚æ‰€ä»¥è¯´learnable querieså®¹æ˜“å­¦ä¹ ï¼ˆåé¢çš„è¿‡ç¨‹å¤§å®¶éƒ½å·®ä¸å¤šï¼Œè¯´æ˜ä»¥åŠå­¦ä¹ å¾—å¾ˆåƒäº†ï¼‰ï¼Œä½†ä¹Ÿæ‹¦ä¸ä½DETRè®­ç»ƒæ…¢ã€‚æ‰€ä»¥ä¸å…çŒœæµ‹ä¸ºç¬¬äºŒä¸ªåŸå› ï¼šæ²¡æœ‰æä¾›æ˜¾å¼ä½ç½®å…ˆéªŒã€‚

![](picture_saved/2024-07-31-17-24-37-image.png)

å°†learnable queriesä¸encoderä¸­çš„positional embeddingè¿›è¡Œç‚¹ä¹˜ï¼Œç„¶åå¯è§†åŒ–ä¹‹ï¼Œå¯ä»¥å‘ç°ï¼Œæ³¨æ„åŠ›å›¾ä¸­è¦ä¸ä¼šå‡ºç°å¤šä¸ªä¸­å¿ƒç‚¹ï¼Œè¦ä¸å°±æ˜¯æ³¨æ„åŠ›é¢ç§¯è¿‡å¤§æˆ–è¿‡å°ï¼Œä¹Ÿå°±è¯´æ˜learnable querieså¹¶æ²¡æœ‰å¾ˆå¥½çš„åœ¨ä½ç½®ä¸Šè¿›è¡Œçº¦æŸã€‚æ—¢æ¯”å¦‚å¦‚æœå›¾ä¸­æœ‰å¤šä¸ªobjectsï¼Œé‚£ä¹ˆqueryå°±ä¸çŸ¥é“è¯¥çœ‹å“ªä¸ªã€‚åˆæˆ–è€…æ˜¯çœ‹çš„ä¸å…¨æˆ–çœ‹çš„å¤ªæ‚ï¼Œæ€»ä¹‹ä¸€ç‚¹ç”¨éƒ½æ²¡æœ‰ã€‚å›¾(b)åˆ™æ˜¯åŠ å…¥äº†ä½ç½®å…ˆéªŒåçš„ç‚¹ä¹˜å¾—å‡ºçš„æ³¨æ„åŠ›å›¾ï¼Œå¯ä»¥å‘ç°æ³¨æ„åŠ›æ˜æ˜¾å¥½å¤šäº†ã€‚

æ‰€ä»¥å¯ä»¥æ¨å‡ºï¼šqueriesçš„å¤šæ¨¡å¼ï¼ˆmultiple mode)æ˜¯å¯¼è‡´è®­ç»ƒæ¼«é•¿çš„ç½ªé­ç¥¸é¦–ï¼Œå¹¶ä¸”åŠ å…¥ä½ç½®å…ˆéªŒæ˜¯å¯ä»¥æœ‰æ•ˆæé«˜è®­ç»ƒé€Ÿåº¦çš„ã€‚

ä½†æ˜¯å›¾(b)ä¹Ÿæœ‰ä¸åˆç†çš„åœ°æ–¹ï¼Œå› ä¸ºä¸åŒçš„objectsçš„å°ºåº¦å¿…ç„¶æ˜¯ä¸åŒçš„ï¼Œå› æ­¤åŠ å…¥å°ºåº¦ä¿¡æ¯ä¹Ÿæ˜¯åº”è¯¥çš„ï¼Œå¦‚å›¾(c)æ‰€ç¤ºã€‚

## 2 Anchor boxes/Reference points

æ‰€ä»¥æœ¬æ–‡æå‡ºäº†anchor boxesä½œä¸ºlearnable queriesï¼Œæ—¢$A_q=(x_q,y_q,w_q,h_q)$è¡¨ç¤ºç¬¬qä¸ªanchor boxã€‚æ•´ä½“æ¨¡å‹å¦‚å›¾æ‰€ç¤º

<img src="picture_saved/2024-07-31-17-28-07-image.png" title="" alt="" width="630">

### 2.1 å„ä¸ªç»„ä»¶

- Decoderä¸­self-attentionçš„Qã€Kçš„ä½ç½®ç¼–ç 
  
  å®ƒç”±reference pointsï¼ˆä¹Ÿå°±æ˜¯anchor boxesï¼‰ç»è¿‡Anchor Sine Encodingï¼ˆæºç ä¸­çš„gen_sineembed_for_positionï¼‰å¾—åˆ°å››ä¸ªæ–¹å‘ç‹¬ç«‹çš„æ­£ä½™å¼¦ç¼–ç åï¼Œåœ¨ç»è¿‡ä¸€å±‚MLPï¼ˆä¸»è¦ä½œç”¨æ˜¯å˜æ¢ç»´åº¦ï¼Œæºç ä¸­çš„ref_point_headï¼‰å¾—åˆ°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„æ¸©åº¦è¿˜æ˜¯10000.

- Decoderä¸­self-attentionçš„è¾“å…¥
  
  ```python
   if not self.rm_self_attn_decoder:
              # Apply projections here
              # shape: num_queries x batch_size x 256
              q_content = self.sa_qcontent_proj(tgt)      # target is the input of the first decoder layer. zero by default.
              q_pos = self.sa_qpos_proj(query_pos)
              k_content = self.sa_kcontent_proj(tgt)
              k_pos = self.sa_kpos_proj(query_pos)
              v = self.sa_v_proj(tgt)
  
              num_queries, bs, n_model = q_content.shape
              hw, _, _ = k_content.shape
  
              q = q_content + q_pos
              k = k_content + k_pos
  
              tgt2 = self.self_attn(q, k, value=v, attn_mask=tgt_mask,
                                  key_padding_mask=tgt_key_padding_mask)[0]
  ```

Â Â Â Â Â Â Â Â å¯è§ä¸ç®¡æ˜¯q,k,vè¿˜æ˜¯position,contentï¼Œéƒ½æ˜¯è¦å…ˆè¿›è¡ŒLinear projectï¼Œç„¶åæ­¤æ—¶contentå’Œposæ˜¯ç›¸åŠ 

- Decoderä¸­cross-attentionçš„x,y transformation
  
  è¿™é‡Œçš„ä½œç”¨æ›´å¤šæ˜¯è·å–ä»¥å†…å®¹ä¿¡æ¯ä¸ºæ¡ä»¶çš„å°ºåº¦å‘é‡ï¼ˆæ—¢è®©å°ºåº¦å‘é‡çœ‹åˆ°å†…å®¹ä¿¡æ¯ï¼Œå†åŠ ä»¥è°ƒæ•´ä¹‹åï¼Œå¾—åˆ°æ–°çš„å°ºåº¦å‘é‡ï¼‰ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç¬¬ä¸€å±‚ä¼ è¿‡æ¥çš„æ˜¯tgtè¢«åˆå§‹åŒ–ä¸º0ï¼Œå¹¶æ²¡æœ‰ä»€ä¹ˆå†…å®¹ä¿¡æ¯ï¼Œæ‰€ä»¥ç¬¬ä¸€å±‚ä¸åštransformationã€‚æ—¢ä»¥ä¸‹å…¬å¼çš„$\text{MLP}^{(csq)}$
  
  ![](picture_saved/2024-07-31-17-50-45-image.png)
  
  ```python
              if self.query_scale_type != 'fix_elewise':
                  if layer_id == 0:
                      pos_transformation = 1
                  else:
                      pos_transformation = self.query_scale(output)
              else:
                  pos_transformation = self.query_scale.weight[layer_id]
  
              # apply transformation
              # æ³¨æ„è¿™é‡Œåšäº†æˆªæ–­ï¼Œåœ¨æœ€åä¸€ç»´æˆªå–å‰ d_model ä¸ªç»´æ•°
              query_sine_embed = query_sine_embed[...,:self.d_model] * pos_transformation
  ```

- Decoderä¸­cross-attentionçš„å°ºåº¦è°ƒèŠ‚
  
  è¿™æ˜¯åŸæœ¬ä¸¤ä¸ªä½ç½®ç¼–ç çš„attention
  
  ![](picture_saved/2024-07-31-17-52-14-image.png)
  
  è¿™æ˜¯åŠ å…¥äº†å°ºåº¦è°ƒèŠ‚åçš„attention
  
  ![](picture_saved/2024-07-31-17-52-40-image.png)
  
  å…·ä½“ä»£ç å®ç°å¦‚ä¸‹ï¼š
  
  ```python
              # modulated HW attentions
              # å°†å°ºåº¦ä¿¡æ¯æ³¨å…¥äº¤å‰æ³¨æ„åŠ›è¿™ä¸€æ­¥éª¤æ˜¯åœ¨attentionä¹‹å‰å®Œæˆçš„
              if self.modulate_hw_attn:
                  refHW_cond = self.ref_anchor_head(output).sigmoid() # nq, bs, 2ï¼Œå¯¹åº”w_{q,ref} & h_{q,ref}
                  query_sine_embed[..., self.d_model // 2:] *= (refHW_cond[..., 0] / obj_center[..., 2]).unsqueeze(-1)
                  query_sine_embed[..., :self.d_model // 2] *= (refHW_cond[..., 1] / obj_center[..., 3]).unsqueeze(-1)
  ```

              output = layer(output, memory, tgt_mask=tgt_mask,
                             memory_mask=memory_mask,
                             tgt_key_padding_mask=tgt_key_padding_mask,
                             memory_key_padding_mask=memory_key_padding_mask,
                             pos=pos, query_pos=query_pos, query_sine_embed=query_sine_embed,
                             is_first=(layer_id == 0))

```
- ä½ç½®åç§»

- æ¯ä¸€å±‚decoderçš„è¾“å‡ºéƒ½ä¼šç»è¿‡MLPï¼ˆbbox_embedï¼‰å¾—åˆ°åç§»é‡ï¼Œç„¶ååŠ å…¥åˆ°å½“å‰çš„reference pointsä¸­å»æ›´æ–°ã€‚æœ€åä¸€å±‚ä¼šåœ¨å¤–éƒ¨è¿›è¡Œã€‚

- bbox_embedåˆ†ä¸ºä¸¤ç§ï¼Œå…±äº«æƒé‡ä»¥åŠæ¯ä¸€å±‚ç‹¬ç«‹

  ä»£ç ç»†èŠ‚å¦‚ä¸‹ï¼š

  ```python
  # decoder å±‚
             # iter update
              # æ›´æ–°å‚è€ƒç‚¹
              if self.bbox_embed is not None: # ç”Ÿæˆoffsets
                  if self.bbox_embed_diff_each_layer:
                      tmp = self.bbox_embed[layer_id](output) # ç‹¬ç«‹
                  else:
                      tmp = self.bbox_embed(output)   # å…±äº«
                  # import ipdb; ipdb.set_trace()
                  tmp[..., :self.query_dim] += inverse_sigmoid(reference_points)  # å‚è€ƒç‚¹æ˜¯ç»è¿‡äº†sigmoidçš„ï¼Œå…ˆåsigmoid
                  new_reference_points = tmp[..., :self.query_dim].sigmoid()  # æ›´æ–°å‚è€ƒç‚¹åé‡æ–°ç»è¿‡sigmoidç¼©æ”¾
                  if layer_id != self.num_layers - 1:
                      ref_points.append(new_reference_points) # æœ€åä¸€å±‚çš„å‚è€ƒç‚¹ä¼šåœ¨å¤–å±‚æ¨¡å‹ç”±æ•´ä¸ªtransformerçš„outputç»è¿‡bbox_embedå¾—åˆ°offsets
                  reference_points = new_reference_points.detach()    ## ä½œè€…è¯´(æœ¬äººè¯´çš„å“¦) detach() æ˜¯å› ä¸ºè®©æ¢¯åº¦çš„æµé€šæ›´å‹å¥½ï¼Œå®ƒæƒ³è®©æ¯å±‚çš„æ¢¯åº¦ä»…å—è¯¥å±‚çš„è¾“å‡ºå½±å“
  ```

  ```python
        # å¤–å±‚
          # iii. é¢„æµ‹æ¯ä¸ªå¯¹è±¡(query)çš„ä½ç½®ï¼š
          # åŸºäºå®ƒä»¬çš„å‚è€ƒç‚¹(ä½ç½®å…ˆéªŒ)ï¼Œç„¶åå°†å®ƒä»¬çš„éšå±‚å‘é‡è¾“å…¥ bbox_embed å¾—åˆ°æ ¡æ­£çš„åç§»é‡ï¼Œ
          # æœ€åç”±å‚è€ƒç‚¹+åç§»é‡å¾—åˆ°ä½ç½®ï¼šx,y,w,h
          if not self.bbox_embed_diff_each_layer:
              reference_before_sigmoid = inverse_sigmoid(reference)
              tmp = self.bbox_embed(hs)
              tmp[..., :self.query_dim] += reference_before_sigmoid
              outputs_coord = tmp.sigmoid()
          else:   # å¦‚æœæ¯ä¸€å±‚çš„bbox_embedä¸å…±äº«
              reference_before_sigmoid = inverse_sigmoid(reference)
              outputs_coords = []
              for lvl in range(hs.shape[0]):  # å¯¹äºæ¯ä¸€å±‚ï¼Œhséƒ½è¦å’Œè¯¥å±‚çš„bbox_embedåš
                  tmp = self.bbox_embed[lvl](hs[lvl])
                  tmp[..., :self.query_dim] += reference_before_sigmoid[lvl]
                  outputs_coord = tmp.sigmoid()
                  outputs_coords.append(outputs_coord)
              outputs_coord = torch.stack(outputs_coords) # (num_layers,bs,num_queries,4)
  ```



- 

- å…¶ä»–ç»†èŠ‚

- å°ºåº¦è°ƒèŠ‚å®åœ¨ä¼ å…¥åˆ°cross-attentionä¹‹å‰è¿›è¡Œçš„

- åœ¨è¾“å…¥åˆ°cross-attentionæ—¶ï¼Œä¼šå°†å…¶è¿›è¡Œconcatè€Œä¸æ˜¯ç›¸åŠ ï¼Œè¿™æ ·contentå’Œpositionçš„æ³¨æ„åŠ›å°±ä¼šåˆ†å¼€è®¡ç®—

- è¿™é‡Œå¯¹äºreference pointså–æ¶ˆäº†æ¢¯åº¦ï¼Œè¿™æ ·çš„è¯å¯ä»¥é¿å…reference pointsè¿‡æ‹Ÿåˆå½“å‰æ•°æ®é›†çš„å°ºå¯¸åˆ†å¸ƒï¼Œå› ä¸ºåç§»é‡ä¹Ÿæ˜¯å¯ä»¥ä¿®æ­£reference pointsçš„ã€‚
```
